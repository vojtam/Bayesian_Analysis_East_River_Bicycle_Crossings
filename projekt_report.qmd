---
title: "East River Bicycle Crossings - Bayesian Analysis"
author: "Vojtěch Máčala"
execute: 
  cache: false
format:
  html:
    other-links:
      - text: U.S. Government Open Data
        href: https://catalog.data.gov/dataset?publisher=data.cityofnewyork.us
    code-links:
      -text: Report online
      href: https://github.com/vojtam/Bayesian_Analysis_East_River_Bicycle_Crossings
    toc: true
    theme: morph
    page-layout: article
    fontsize: 1.3em
    embed-resources: true
    logo: bike_logo.png
    lightbox: true
    code-tools: true
    code-block-bg: true
    code-copy: hover
    code-link: true
    code-block-border-left: "#31BAE9"
    code-fold: true
---

# New York City - East River Bicycle Crossings

This project focuses on analyzing cyclist crossings over bridges in New York City.

## Dataset

The New York City Department of Transportation collects daily data on the number of bicycles crossing bridges in NYC. This data is used to measure bicycle usage for transportation planning. This dataset is a daily record of the number of bicycles entering or leaving Manhattan via one of the East River bridges (i.e., excluding crossings in the Bronx and Hudson River tunnels, which are not intended for cyclists) over a 9-month period.

![Historical map of East Side bridges](./bridges.jpg)

```{r}
#| column: screen
library(leaflet)
leaflet() %>%
    addTiles() %>%
    addMarkers(lat = 40.756944, lng = -73.954722, popup = "Queensboro Bridge") %>%
    addMarkers(lat = 40.707, lng = -73.9905, popup = "Manhattan Bridge") %>%
    addMarkers(lat = 40.7057, lng = -73.9964, popup = "Bro Bridge") %>%
    addMarkers(lat = 40.7125, lng = -73.9725, popup = "Williamsburg Bridge")



```

## Explorative Data Analysis, Data Preprocessing

```{r}
#| warning: false
#| echo: false

suppressPackageStartupMessages({
  library(bslib)
  library(dplyr)
  library(tidyr)
  library(ggplot2)
  library(data.table)
  library(DT)
  library(patchwork)
  library(Hmisc)
  library(readODS)
  library(ggcorrplot)
  library(plotly)
  library(HDInterval)
  library(reticulate)
})

py_require("pandas")
py_require("plotly")
source("./poisson_model.R")
```

```{r}
data_path <- file.path("data/bike_data.ods")
data <- read_ods(data_path)
glimpse(data)

data <- data |> mutate(
        precipitation = ifelse(Precipitation == "T", "0.01", Precipitation) |> as.double(),
        high_temp_C = (`High Temp (°F)` - 32)  *   ( 5 / 9),
        low_temp_C = (`Low Temp (°F)` - 32)  *   ( 5 / 9)
)

data <- data |> mutate(
        precipitation = precipitation * 25.4 # convert precipitation form inches to mm
)

data <- data |> mutate(
        is_rainy = precipitation > 1,
        is_weekend = Day %in% c("Saturday", "Sunday")
)

data$week_index <- c(0, rep(1:(nrow(data)      -   1)  %/% 7))
data_filtered <- select(data, !c("High Temp (°F)", "Low Temp (°F)", "Precipitation"))

data.table::setnames(data_filtered, old = c("Date", "Day", "Total", "Brooklyn Bridge", "Manhattan Bridge", "Williamsburg Bridge", "Queensboro Bridge"), new = c("date", "day", "total", "brooklyn", "manhattan", "williamsburg", "queensboro"))

data_long <- data_filtered |> pivot_longer(cols = c("brooklyn", "manhattan", "williamsburg", "queensboro", "total"))
```

The data contains, for each of the $214$ measured days, information on the number of cyclists on the monitored bridges. Additionally, it includes some meteorological data, specifically the highest and lowest recorded temperatures for the day, as well as the total precipitation.

For easier work and better interpretation, I converted the temperature data to degrees Celsius and the precipitation data to $mm^3$.

According to studies by Richardson (2000) and Phung and Rose (2007), rain is the parameter that most affects the number of cyclists in Melbourne. Therefore, I decided to create models based on whether it rained on a given day.

Subsequently, for easier aggregation, I created a categorical variable `is_rainy`, considering a day rainy if at least one millimeter of precipitation fell during it.

The resulting data looks as follows.
```{r}
data <- fread("data/bike_data_filtered.csv")
data_long <- fread("data/bike_data_filtered_long.csv")
glimpse(data)


#' @export
get_weekly_tab <- function(daily_data, var) {
        weekly_tab <- daily_data  |>
         group_by(week_index) |>
                summarise(
                        weekly_total  = sum( get ({{ var }})),
                        high_temp_median = median(high_temp_C),
                        low_temp_median = median(low_temp_C),
                        mean_precipitation = mean(precipitation)
                )
}

#' @export
get_bridge_tab <- function(data, var) {
        data |> filter(name == var)
}

brooklyn_weekly <- get_weekly_tab(data, "brooklyn")

```

For some tasks, data in the `long` format is more suitable. By pivoting, I also created this table.

```{r}
glimpse(data_long)
```

```{r}
summary(data)
```

```{r}
var(data$brooklyn)
```

```{r}
ggplot(brooklyn_weekly, aes(x = week_index, y = weekly_total)) +
        geom_bar(stat = "identity", color = "black", fill = "darkorchid") +
        labs(x = "Week index", y = 'Number of cyclists in the given week')
```
In this graph, we can see that the average weekly number of cyclists across all bridges combined stays around 15 to 20 thousand. It can also be observed that, except for the second observed week, the number of cyclists in the first few (spring) weeks is lower than for the rest of the monitored period.

```{r}
M <- as.matrix(data |> select(brooklyn, manhattan, williamsburg, queensboro, total, precipitation, high_temp_C, low_temp_C, week_index))
R_sp<- rcorr(M, type = "spearman")
diag(R_sp$P) <- 0

spearman_plot <- ggcorrplot::ggcorrplot(R_sp$r, p.mat = R_sp$P, title = "Spearman's correlations", 
  lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)

# R <- rcorr(M, type = "pearson")
# diag(R$P) <- 0
# 
# pearson_plot <- ggcorrplot::ggcorrplot(R$r, p.mat = R$P, title = "Pearson's correlations", 
#   lab = TRUE, type = "full", method = "square", outline.color = "white", show.legend = FALSE, pch.cex = 10)
# 
# pearson_plot + spearman_plot
spearman_plot
```

Looking at the Spearman's correlation coefficient matrix, one can see (as expected) a negative correlation between the number of cyclists and precipitation totals. A positive correlation between the number of cyclists and temperature can also be observed.

```{r}
ggplot(data_long, aes(x = name, y = value, fill = name)) +
        geom_boxplot() +
        labs(
          title = "Daily Bicycle Counts by Bridge",
           x = "Bridge",
          y = "Daily Bicycle Count"
    ) +
    theme(axis.text.x = element_text(angle = -45, hjust = 0)) # Rotate x-axis labels for readability
```

```{r}
  ggplot(data_long, aes(sample = value, colour = factor(name))) +
    stat_qq() +
    stat_qq_line() +
    labs(x = "Theoretical Quantiles", y = "Empirical Quantiles")
```
On the QQ plot, we can see that for most groups, we have reason to believe that normality is significantly violated.

## Bayesian Analysis

The goal of the analysis is to determine how the number of cyclists on the monitored bridges changes during the observation period.

### Poisson Model

We observe i.i.d Poisson random variables $(Y_k \mid \theta) \sim \text{Po}(\theta), \; \; k = 1, \dots , n$.

Our parameter space is $\mathcal{T} = (0, \infty)$ and the sample space $\mathcal{Y} = \mathcal{N}_0$.

The sufficient statistic is the total number of cyclists during the monitored period: $Y = \sum_{k = 1}^n Y_k$. The experiment then has the distribution: $$(Y\mid \theta) \sim \text{Po}(n \theta)$$

The likelihood function has the form:

$$
f(y \mid \theta) \propto L(\theta; y) = (n \theta)^y e^{-n \theta}
$$

The posterior distribution is then defined as follows:

$$
(\Theta \mid Y = y) \sim \text{Gamma}(a + y, b + n)
$$

Some numerical characteristics of the posterior distribution:

$$
E(\Theta \mid Y = y) = \frac{a + y}{b + n}, \; \; Var(\Theta \mid Y = y) = \frac{a + y}{(b + n)^2}, \;\; \text{Mode}(\Theta \mid Y = y) = \frac{a + y - 1}{b + n}
$$

## Rainy vs Dry Days

The first question that interested me about the data is to what extent the presence of rain affects the number of cyclists.

For the prior model of the number of cyclists on days when it rained, I consulted available relevant literature. Keay (1992) found that light rain deterred up to 50% of surveyed women from cycling. Nankervis (1999) reported a 67% decrease in cyclists due to heavy rain. Phang and Rose (2007) then state "only" a 13 - 25% decrease in cyclists during rain in Melbourne.

For the model of the number of cyclists on days when it rained, I therefore decided on (rather vague) prior information that in these cases the prior mean value would be 40% lower than on "dry" days.

### Choice of Prior and Posterior Distribution

Since we have no precise prior information about the parameter $\theta$, we will use only a weakly informative distribution. A suitable choice is the Gamma distribution, as it forms a conjugate family of densities for the Poisson model.

The prior distribution thus looks as follows: $$
\Theta \sim \text{Gamma}(a, b), \quad \mathcal{T} = (0; \infty), \quad a,b > 0, \quad p(\theta) \propto \theta^{a - 1}e^{-b\theta}{b}
$$


Some of the numerical characteristics of this distribution: $$
E(\Theta) = \frac{a}{b}, \quad Var(\Theta) = \frac{a}{b^2}, \quad Mode(\Theta) = \frac{a - 1}{b}
$$

The mean of the posterior distribution can be written as a convex combination of the prior mean and the sample mean: $$
E(\Theta \mid y) = \frac{b}{b + n} E(\Theta) + \frac{n}{b + n} \bar{y}
$$

Due to the lack of prior knowledge, I tried to choose the parameters of the prior distribution such that the prior mean was close to the sample mean and the prior variance was much larger than the sample variance. In all cases, I chose $b = 0.001 << n$, which results in $E(\Theta \mid y) \approx \bar{y}, \quad Var(\Theta \mid y) \approx \frac{\bar{y}}{n}$. Thus, I let the data "speak for itself".


From the discussion above regarding the fluctuation in the number of cyclists during rainy days, I decided to create a convex mixture of two prior densities: one for rainy and one for dry days.

This mixture will have the density:
$$
p(\theta) = \sum_{i = 1}^2 w_i p_i(\theta)
$$
where $\sum_{i = 1}^2 w_i = 1$

The weight of the "rainy" distribution is given by the proportion of rainy days (approximately 0.3); I proceeded similarly when choosing the weight for the "dry" distribution.

Because the prior distribution is a convex mixture, the posterior distribution will also be a mixture.

The specific choices of parameters for the individual densities that make up the mixture are listed in the box for each monitored bridge.


```{r}
get_characteristics_df <- function(bridge_name, dry_a, dry_b, rainy_a, rainy_b, n_dry, y_dry, dry_post_tab, n_rainy, y_rainy, rainy_post_tab, weight_dry, weight_rainy) {
  dry_prior_characteristics_df <- get_prior_poisson_characteristics(dry_a, dry_b, paste(bridge_name, "Dry prior"))
  dry_prior_characteristics_df <- dry_prior_characteristics_df |> mutate(weight = weight_dry)
  rainy_prior_characteristics_df <- get_prior_poisson_characteristics(rainy_a, rainy_b, paste(bridge_name, "Rainy prior"))
  rainy_prior_characteristics_df <- rainy_prior_characteristics_df |> mutate(weight = weight_rainy)
  
  
  dry_characteristics_df <- get_posterior_poisson_characteristics(
    dry_a,
    dry_b,
    n_dry,
    y_dry,
    dry_post_tab,
    paste(bridge_name, "Dry posterior")
  )
  dry_characteristics_df <- dry_characteristics_df |>  mutate(weight = weight_dry)

  rainy_characteristics_df <- get_posterior_poisson_characteristics(
    rainy_a,
    rainy_b,
    n_rainy,
    y_rainy,
    rainy_post_tab,
    paste(bridge_name, "Rainy posterior")
  )
  rainy_characteristics_df <- rainy_characteristics_df |> mutate(weight = weight_rainy)
  
  combined_prior_characteristics <- bind_rows(dry_prior_characteristics_df, rainy_prior_characteristics_df) |>
    summarise(
      mean = sum(mean * weight),
      SD = sqrt(sum((SD^2 + mean^2) * weight) - sum(mean * weight)^2),
      ETCI.lwr = sum(ETCI.lwr * weight),
      ETCI.upr = sum(ETCI.upr * weight),
      HPD.lower = sum(HPD.lower * weight),
      HPD.upper = sum(HPD.upper * weight)
    ) |>
    mutate(
      MLE = NA,
      MAP = NA,
      model = paste(bridge_name, "prior")
    )
  
  combined_posterior_characteristics <- bind_rows(dry_characteristics_df, rainy_characteristics_df) %>%
    summarise(
      MLE = sum(MLE * weight),
      MAP = sum(MAP * weight),
      mean = sum(mean * weight),
      SD = sqrt(sum((SD^2 + mean^2) * weight) - sum(mean * weight)^2),
      ETCI.lwr = sum(ETCI.lwr * weight),
      ETCI.upr = sum(ETCI.upr * weight),
      HPD.lower = sum(HPD.lower * weight),
      HPD.upper = sum(HPD.upper * weight)
    ) |>
    mutate(model = paste(bridge_name, "posterior"))

  characteristics_df <- rbind(combined_prior_characteristics, combined_posterior_characteristics)
  setnames(characteristics_df, c("HPD.lower", "HPD.upper"), c("HPD.lwr", "HPD.upr"))
  return(characteristics_df)
}
```

```{r}
get_characteristics_reactable <- function(characteristics_df) {
  if (colnames(characteristics_df)[length(characteristics_df)] == "model") {
    characteristics_df <- characteristics_df[,c(length(characteristics_df), 1:(length(characteristics_df) - 1))]
  }
  datatable(
    characteristics_df,
    options = list(
      pageLength = 16,
      lengthMenu = c(5, 10, 15, 20)
    )
  ) |>
    formatRound(colnames(characteristics_df)[2:ncol(characteristics_df)], digits = 2, mark = "") |>
    formatStyle(colnames(characteristics_df), 'text-align' = 'center')
}

```

```{r}
dist_mixture <- function(dist_A, dist_B, weight_A, weight_B, model_name, grp_by = "theta"){
  dist_A <- dist_A |> mutate(weight = weight_A)
  dist_B <- dist_B |> mutate(weight = weight_B)
  dist_mix <- bind_rows(dist_A, dist_B)
  
  weighted_mixture <- dist_mix |>
    group_by(!!sym(grp_by)) |>
    summarise(
      p = sum(weight * p),
      model = model_name,
      .groups = 'drop'
    )
  return(weighted_mixture)
}

```



```{r}
get_bridge_analysis <- function(bridge_name, theta_start, theta_end, priors_param_tab) {
  bridge_data <- get_bridge_tab(data_long, bridge_name)
  prior_tab_dry <- with(priors_param_tab, get_poisson_prior_tab(theta_start, theta_end, dry_prior_a, dry_prior_b, 0.1, paste(bridge_name, "Dry prior")))

  prior_tab_rainy <- with(priors_param_tab, get_poisson_prior_tab(theta_start, theta_end, rainy_prior_a, rainy_prior_b, 0.1, paste(bridge_name, "Rainy prior")))

  # prior <- bind_rows(prior_tab_dry, prior_tab_rainy)
  prior <- dist_mixture(prior_tab_dry, prior_tab_rainy, 0.7, 0.3, paste(bridge_name, "prior"))

  theta <- prior_tab_dry$theta
  dry_data <- bridge_data |> filter(!is_rainy)
  rainy_data <- bridge_data |> filter(is_rainy)

  n_dry <- nrow(dry_data)
  y_dry <- sum(dry_data$value)
  n_rainy <- nrow(rainy_data)
  y_rainy <- sum(rainy_data$value)
  
  dry_weight <- n_dry / (n_dry + n_rainy)
  rainy_weight <- n_rainy / (n_dry + n_rainy)

  posterior_tab_dry <- with(priors_param_tab, get_poisson_posterior_tab(dry_prior_a, dry_prior_b, n_dry, y_dry, theta, paste(bridge_name, "Dry posterior")))
  posterior_tab_rainy <- with(priors_param_tab, get_poisson_posterior_tab(rainy_prior_a, rainy_prior_b, n_rainy, y_rainy, theta, paste(bridge_name, "Rainy posterior")))

  # posterior <- bind_rows(posterior_tab_dry, posterior_tab_rainy)
  posterior <- dist_mixture(posterior_tab_dry, posterior_tab_rainy, dry_weight, rainy_weight, paste(bridge_name, "posterior"))

  likelihood_tab_dry <- get_poisson_likelihood_tab(n_dry, y_dry, theta, 10, paste(bridge_name, "Dry likelihood"))
  likelihood_tab_rainy <- get_poisson_likelihood_tab(n_rainy, y_rainy, theta, 10, paste(bridge_name, "Rainy likelihood"))

  # likelihood <- bind_rows(likelihood_tab_dry, likelihood_tab_rainy)
  likelihood <- dist_mixture(likelihood_tab_dry, likelihood_tab_rainy, dry_weight, rainy_weight, paste(bridge_name, "likelihood"))

  full_tab <- bind_rows(prior, posterior, likelihood)

  characteristics_tab <- with(priors_param_tab, get_characteristics_df(bridge_name, dry_prior_a, dry_prior_b, rainy_prior_a, rainy_prior_b, n_dry, y_dry, posterior_tab_dry, n_rainy, y_rainy, posterior_tab_rainy, dry_weight, rainy_weight))
  return(list(tab = full_tab, characteristics = characteristics_tab))
}
```

```{R}
get_zoomed_plots <- function(full_tab, rainy_xlim_vec, dry_xlim_vec) {
  dry_plot <- full_tab |> filter(
    grepl("Dry", model)
  ) |>
  get_distribution_plot() +
    xlim(dry_xlim_vec) +
    theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))

rainy_plot <- full_tab |> filter(
    grepl("Rainy", model)
  ) |>
  get_distribution_plot() +
    xlim(rainy_xlim_vec) +
    theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))

  return(rainy_plot + dry_plot)
}
```

```{r}
get_plot <- function(tab) {
  return(ggplotly(get_distribution_plot(tab)))
}
```

::: {.panel-tabset style="background: #cbdffc; padding-top: 1rem; padding-bottom: 1rem;"}
## Brooklyn

$$
\text{dry:} \qquad a = 3, \quad b = 0.001
$$

$$
\text{rainy:} \qquad a = 1.8, \quad b = 0.001
$$
$$
p(\theta) =  w_{\text{dry}} * p(\theta)_{\text{dry}} + w_{\text{rainy}} + p(\theta)_{\text{rainy}}
$$

```{r}
brooklyn_precip_prior_params <- list(dry_prior_a = 3, dry_prior_b = 0.001, rainy_prior_a = 1.8, rainy_prior_b = 0.001)
bridge_results_brooklyn <- get_bridge_analysis("brooklyn", 0, 3200, brooklyn_precip_prior_params)
fwrite(bridge_results_brooklyn$tab, "data/brooklyn_full_tab.csv")
```

```{python}
#| column: screen
#| out-width: 100%
import pandas as pd
import plotly.express as px

def get_plotly_distribution_plot(full_tab):
    fig = px.line(full_tab, x='theta', y='p', color='model', line_group='model', labels={'p': 'Probability', 'theta': 'Theta'}, title='Distribution Plot')
    return fig
  
tab = pd.read_csv("./data/brooklyn_full_tab.csv")
get_plotly_distribution_plot(tab).show()
```


```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_brooklyn$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)
```

## Manhattan

$$
\text{dry:} \qquad a = 5.3, \quad b = 0.001
$$

$$
\text{rainy:} \qquad a = 3, \quad b = 0.001
$$
$$
p(\theta) =  w_{\text{dry}} * p(\theta)_{\text{dry}} + w_{\text{rainy}} + p(\theta)_{\text{rainy}}
$$

```{r}
manhattan_precip_prior_params <- list(dry_prior_a = 5.3, dry_prior_b = 0.001, rainy_prior_a = 3.18, rainy_prior_b = 0.001)
bridge_results_manhattan <- get_bridge_analysis("manhattan", 0, 7500, manhattan_precip_prior_params)
fwrite(bridge_results_manhattan$tab, "data/manhattan_full_tab.csv")
```

```{python}
#| column: screen
#| out-width: 100%
#| warning: false
tab = pd.read_csv("./data/manhattan_full_tab.csv")
get_plotly_distribution_plot(tab).show()
```


```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_manhattan$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab,
     shiny::markdown("The prior distribution has a mean value of 5300 cyclists for dry days and 3180 for rainy days. We can see that on days without precipitation, the posterior expected number of cyclists on the Manhattan bridge is 5964, and on rainy days it is 3512. From this, it is clear that the prior information was slightly underestimated. However, looking at the MLE and MAP estimates, it is evident that the prior information had a negligible effect on these results, mainly due to the huge prior variance.")
  )

```

## Queensboro

$$
\text{dry:} \qquad a = 4.5, \quad b = 0.001
$$

$$
\text{rainy:} \qquad a = 2.7, \quad b = 0.001
$$
$$
p(\theta) =  w_{\text{dry}} * p(\theta)_{\text{dry}} + w_{\text{rainy}} + p(\theta)_{\text{rainy}}
$$

```{r}
queensboro_precip_prior_params <- list(dry_prior_a = 4.5, dry_prior_b = 0.001, rainy_prior_a = 2.7, rainy_prior_b = 0.001)
bridge_results_queensboro <- get_bridge_analysis("queensboro", 0, 5500, queensboro_precip_prior_params)
fwrite(bridge_results_queensboro$tab, "data/queensboro_full_tab.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/queensboro_full_tab.csv")
get_plotly_distribution_plot(tab).show()
```


```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_queensboro$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## Williamsburg

$$
\text{dry:} \qquad a = 6, \quad b = 0.001
$$

$$
\text{rainy:} \qquad a = 3.6, \quad b = 0.001
$$
$$
p(\theta) =  w_{\text{dry}} * p(\theta)_{\text{dry}} + w_{\text{rainy}} + p(\theta)_{\text{rainy}}
$$

```{r}
williamsburg_precip_prior_params <- list(dry_prior_a = 6, dry_prior_b = 0.001, rainy_prior_a = 3.6, rainy_prior_b = 0.001)
bridge_results_williamsburg <- get_bridge_analysis("williamsburg", 0, 8500, williamsburg_precip_prior_params)
fwrite(bridge_results_williamsburg$tab, "data/williamsburg_full_tab.csv")


```

```{python}
#| column: screen
#| out-width: 100%
import pandas as pd

def get_plotly_distribution_plot(full_tab):
    fig = px.line(full_tab, x='theta', y='p', color='model', line_group='model', labels={'p': 'Probability', 'theta': 'Theta'}, title='Distribution Plot')
    return fig

tab = pd.read_csv("./data/williamsburg_full_tab.csv")
get_plotly_distribution_plot(tab).show()
```


```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_williamsburg$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## Total

$$
\text{dry:} \qquad a = 18.5, \quad b = 0.001
$$ $$
\text{rainy:} \qquad a = 11.1, \quad b = 0.001
$$
$$
p(\theta) =  w_{\text{dry}} * p(\theta)_{\text{dry}} + w_{\text{rainy}} + p(\theta)_{\text{rainy}}
$$

```{r}
total_precip_prior_params <- list(dry_prior_a = 18.5, dry_prior_b = 0.001, rainy_prior_a = 11.1, rainy_prior_b = 0.001)
bridge_results_total <- get_bridge_analysis("total", 0, 23000, total_precip_prior_params)
fwrite(bridge_results_total$tab, "data/total_full_tab.csv")


```

```{python}
#| column: screen
#| out-width: 100%
import pandas as pd

def get_plotly_distribution_plot(full_tab):
    fig = px.line(full_tab, x='theta', y='p', color='model', line_group='model', labels={'p': 'Probability', 'theta': 'Theta'}, title='Distribution Plot')
    return fig

tab = pd.read_csv("./data/total_full_tab.csv")
#get_plotly_distribution_plot(tab).show()
```

```{r}
get_distribution_plot(bridge_results_total$tab) |> print()
```


```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_total$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

$$
\text{rainy:} \qquad a = 11.1, \quad b = 0.001
$$
:::

```{r}
tab_all_bridges <- bind_rows(
  bridge_results_brooklyn$tab,
  bridge_results_manhattan$tab,
  bridge_results_queensboro$tab,
  bridge_results_williamsburg$tab
)

characteristics_all_bridges <- bind_rows(
  bridge_results_brooklyn$characteristics,
  bridge_results_manhattan$characteristics,
  bridge_results_queensboro$characteristics,
  bridge_results_williamsburg$characteristics
)

fwrite(tab_all_bridges, "data/tab_all_bridges.csv")

```

### Characteristics of All Distributions
```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- characteristics_all_bridges |> get_characteristics_reactable()
card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab
  )
```

As expected, it is confirmed that the mean and MAP are lower for all bridges on rainy days. It is also clear that our prior distribution is very weakly informative, and the achieved results hardly differ from the maximum likelihood estimates.

```{python}
#| warning: false
#| echo: false
#tab = pd.read_csv("./data/tab_all_bridges.csv")
#get_plotly_distribution_plot(tab).show()
```

## Predictive Distribution

Finally, it is appropriate to also look at the possibility of prediction for future (hitherto unobserved) days. We will therefore construct the predictive distribution.

The predictive distribution in the Poisson model has a negative binomial distribution:

$$
(Y^*_{n + 1} \mid Y = y) \sim \text{NBi}\biggl(a + y, \frac{b + n}{b + n + 1}\biggl)
$$

Selected numerical characteristics of this distribution look as follows:

$$
E(Y^*_{n + 1} \mid Y = y) = \frac{a + y}{b + n} \quad Var(Y^*_{n + 1} \mid Y =y) = \frac{(a + y) (b + n + 1)}{(b + n)^2}
$$



```{r}

mix_pred <- function(dist_A, dist_B, weight_A, weight_B, model_name, grp_by = "y.pred"){
  dist_A <- dist_A |> mutate(weight = weight_A)
  dist_B <- dist_B |> mutate(weight = weight_B)
  dist_mix <- bind_rows(dist_A, dist_B)
  
  weighted_mixture <- dist_mix |>
    group_by(!!sym(grp_by)) |>
    summarise(
      f = sum(weight * f),
      model = model_name,
      .groups = 'drop'
    )
  return(weighted_mixture)
}

plot_predictive <- function(pred_start, pred_end, prior_params, bridge_name) {
  predict_dry_tab <- with(prior_params, predict_neg_bin_prior(pred_start, pred_end, dry_prior_a, dry_prior_b, "Dry marginal"))
  
  predict_rainy_tab <- with(prior_params, predict_neg_bin_prior(pred_start, pred_end, rainy_prior_a, rainy_prior_b, "Rainy marginal"))
  
  
  marginal <- mix_pred(predict_dry_tab, predict_rainy_tab, 0.7, 0.3, "marginal", "y.pred")
  
  bridge_data <- get_bridge_tab(data_long, bridge_name)
  dry_data <- bridge_data |> filter(!is_rainy)
  rainy_data <- bridge_data |> filter(is_rainy)
  
  n_dry <- nrow(dry_data)
  y_dry <- sum(dry_data$value)
  n_rainy <- nrow(rainy_data)
  y_rainy <- sum(rainy_data$value)
  
  dry_weight <- n_dry / (n_dry + n_rainy)
  rainy_weight <- n_rainy / (n_dry + n_rainy)
  
  post_pred_dry <- with(prior_params, predict_neg_bin_posterior(pred_start, pred_end, dry_prior_a, dry_prior_b, y_dry, n_dry, 1, "Dry posterior"))
  post_pred_rainy <- with(prior_params, predict_neg_bin_posterior(pred_start, pred_end, rainy_prior_a, rainy_prior_b, y_rainy, n_rainy, 1, "Rainy posterior"))
  
  post_predict <- mix_pred(post_pred_dry, post_pred_rainy, dry_weight, rainy_weight, "posterior", "y.pred")
  
  pred_full <- rbind(marginal, post_predict)
  
  predict_plot <- get_predict_dist_plots(pred_full, "Predicted number of cyclists")
  print(predict_plot)
}

characteristics_pred_card <- function(prior_params, bridge_name) {
  bridge_data <- get_bridge_tab(data_long, bridge_name)
  dry_data <- bridge_data |> filter(!is_rainy)
  rainy_data <- bridge_data |> filter(is_rainy)
  
  n_dry <- nrow(dry_data)
  y_dry <- sum(dry_data$value)
  n_rainy <- nrow(rainy_data)
  y_rainy <- sum(rainy_data$value)
  
  dry_weight <- n_dry / (n_dry + n_rainy)
  rainy_weight <- n_rainy / (n_dry + n_rainy)
  
  dry_marginal_characteristics <- with(prior_params, predict_neg_bin_marginal_characteristics(dry_prior_a, dry_prior_b, "Dry marginal"))
  dry_marginal_characteristics <- dry_marginal_characteristics |> mutate(weight = dry_weight)
  rainy_marginal_characteristics <- with(prior_params, predict_neg_bin_marginal_characteristics(rainy_prior_a, rainy_prior_b, "Rainy marginal"))
  rainy_marginal_characteristics <- rainy_marginal_characteristics |> mutate(weight = rainy_weight)
  
  combined_marginal_characteristics <- bind_rows(dry_marginal_characteristics, rainy_marginal_characteristics) %>%
    summarise(
      mean = sum(mean * weight),
      SD = sqrt(sum((SD^2 + mean^2) * weight) - sum(mean * weight)^2),
      lower = sum(lower * weight),
      upper = sum(upper * weight),
    ) |>
    mutate(model = paste(bridge_name, "marginal predictive"))
  
  dry_posterior_characteristics <- with(prior_params, predict_neg_bin_posterior_characteristics(dry_prior_a, dry_prior_b, y_dry, n_dry, "Dry posterior"))
  dry_posterior_characteristics <- dry_posterior_characteristics |> mutate(weight = dry_weight)
  rainy_posterior_characteristics <- with(prior_params, predict_neg_bin_posterior_characteristics(rainy_prior_a, rainy_prior_b, y_rainy, n_rainy, "Rainy posterior"))
  rainy_posterior_characteristics <- rainy_posterior_characteristics |> mutate(weight = rainy_weight)

  combined_posterior_characteristics <- bind_rows(dry_posterior_characteristics, rainy_posterior_characteristics) %>%
    summarise(
      mean = sum(mean * weight),
      SD = sqrt(sum((SD^2 + mean^2) * weight) - sum(mean * weight)^2),
      lower = sum(lower * weight),
      upper = sum(upper * weight),
    ) |>
    mutate(model = paste(bridge_name, "posterior predictive"))
  
  pred_characteristics_df <- bind_rows(combined_marginal_characteristics, combined_posterior_characteristics)
  pred_characteristics_DT <- get_characteristics_reactable(pred_characteristics_df)
  
  card(full_screen = TRUE,
       card_header(
         class = "bg-dark",
         paste(bridge_name, "Predictive Distribution Characteristics")
       ),
       pred_characteristics_DT)
}

```

::: {.panel-tabset style="background: #cbdffc; padding-top: 1rem; padding-bottom: 1rem;"}
## Brooklyn

```{r}
plot_predictive(0, 3500, brooklyn_precip_prior_params, "brooklyn")

```

```{r}
#| column: screen
#| out-width: 100%
characteristics_pred_card(brooklyn_precip_prior_params, "brooklyn")
```

## Manhattan

```{r}
plot_predictive(0, 7000, manhattan_precip_prior_params, "manhattan")

```

```{r}
#| column: screen
#| out-width: 100%
characteristics_pred_card(manhattan_precip_prior_params, "manhattan")
```

## Queensboro

```{r}
plot_predictive(0, 5500, queensboro_precip_prior_params, "queensboro")

```

```{r}
#| column: screen
#| out-width: 100%
characteristics_pred_card(queensboro_precip_prior_params, "queensboro")
```

## Williamsburg

```{r}
plot_predictive(0, 8000, williamsburg_precip_prior_params, "williamsburg")

```

```{r}
#| column: screen
#| out-width: 100%
characteristics_pred_card(williamsburg_precip_prior_params, "williamsburg")
```
:::

## Weekdays vs Weekend Days

Another question I would like to answer is how the distribution of cyclists differs between weekends and weekdays. It is possible that there will be more cyclists during weekdays due to commuting to work. However, it is equally possible that there will be more people exercising on the weekend, and thus more cyclists.

### Choice of Prior Distribution

Once more, we do not have precise prior information about the parameter $\theta$. I also do not want to rely on existing literature, and therefore I will choose a completely non-informative distribution in the form of Jeffreys' prior. For simplicity, I will again work with the conjugate family of densities.

Jeffreys' prior has the form $p(\theta) \propto \frac{1}{\sqrt{\theta}}$, which corresponds in the limit to the distribution $Gamma(a = \frac{1}{2}, b = 0)$.

```{r}
get_characteristics_day_df <- function(bridge_name, prior_a, prior_b, n_weekday, y_weekday, weekday_post_tab, n_weekend, y_weekend, weekend_post_tab) {
  #prior_characteristics_df <- get_prior_poisson_characteristics(prior_a, prior_b, paste(bridge_name, "prior"))
  weekday_characteristics_df <- get_posterior_poisson_characteristics(
    prior_a,
    prior_b,
    n_weekday,
    y_weekday,
    weekday_post_tab,
    paste(bridge_name, "Weekday posterior")
  )

  weekend_characteristics_df <- get_posterior_poisson_characteristics(
    prior_a,
    prior_b,
    n_weekend,
    y_weekend,
    weekend_post_tab,
    paste(bridge_name, "Weekend posterior")
  )

  characteristics_df <- rbind(weekday_characteristics_df, weekend_characteristics_df)
  setnames(characteristics_df, c("HPD.lower", "HPD.upper"), c("HPD.lwr", "HPD.upr"))
  return(characteristics_df)
}
```

```{r}
get_bridge_day_analysis <- function(bridge_name, data_long, theta_start, theta_end, priors_param_tab) {
  bridge_data <- get_bridge_tab(data_long, bridge_name)

  prior_tab <- with(priors_param_tab, get_poisson_prior_tab(theta_start, theta_end, prior_a, prior_b, 0.1,  "prior", TRUE))


  theta <- prior_tab$theta
  weekday_data <- bridge_data |> filter(!is_weekend)
  weekend_data <- bridge_data |> filter(is_weekend)

  n_weekday <- nrow(weekday_data)
  y_weekday <- sum(weekday_data$value)
  n_weekend <- nrow(weekend_data)
  y_weekend <- sum(weekend_data$value)

  posterior_tab_weekday <- with(priors_param_tab, get_poisson_posterior_tab(prior_a, prior_b, n_weekday, y_weekday, theta, paste(bridge_name, "Weekday posterior")))
  posterior_tab_weekend <- with(priors_param_tab, get_poisson_posterior_tab(prior_a, prior_b, n_weekend, y_weekend, theta, paste(bridge_name, "Weekend posterior")))

  posterior <- bind_rows(posterior_tab_weekday, posterior_tab_weekend)

  likelihood_tab_weekday <- get_poisson_likelihood_tab(n_weekday, y_weekday, theta, 10, paste(bridge_name, "Weekday likelihood"))
  likelihood_tab_weekend <- get_poisson_likelihood_tab(n_weekend, y_weekend, theta, 10, paste(bridge_name, "Weekend likelihood"))

  likelihood <- bind_rows(likelihood_tab_weekday, likelihood_tab_weekend)

  full_tab <- bind_rows(prior_tab, posterior, likelihood)

  characteristics_tab <- with(priors_param_tab, get_characteristics_day_df(bridge_name, prior_a, prior_b, n_weekday, y_weekday, posterior_tab_weekday, n_weekend, y_weekend, posterior_tab_weekend))
  return(list(tab = full_tab, characteristics = characteristics_tab))
}
```

```{R}
get_zoomed_plots <- function(full_tab, weekend_xlim_vec, weekday_xlim_vec) {
  weekday_tab <- full_tab |> filter(
    grepl("Weekday|prior", model)
  )
  
  weekday_plot <- weekday_tab |> get_distribution_plot() +
    xlim(weekday_xlim_vec) +
    ylim(c(0, 0.1)) +
    theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))

  weekend_tab <- full_tab |> filter(
    grepl("Weekend|prior", model)
  )
weekend_plot <- weekend_tab |>
  get_distribution_plot() +
    xlim(weekend_xlim_vec) +
    ylim(c(0, 0.1)) +
    theme(axis.text.x = element_text(angle=45, vjust=1, hjust=1))

  return(weekend_plot + weekday_plot)
}
```

::: {.panel-tabset style="background: #cbdffc; padding-top: 1rem; padding-bottom: 1rem;"}
## brooklyn


```{r}
brooklyn_day_prior_params <- list(prior_a = 1/2, prior_b = 0)
bridge_results_brooklyn_day <- get_bridge_day_analysis("brooklyn", data_long, 0, 5500, brooklyn_day_prior_params)
fwrite(bridge_results_brooklyn_day$tab, "data/brooklyn_full_tab_day.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/brooklyn_full_tab_day.csv")

def get_plotly_distribution_plot(full_tab):
    fig = px.line(full_tab, x='theta', y='p', color='model', line_group='model', labels={'p': 'Probability', 'theta': 'Theta'}, title='Distribution Plot')
    fig.update_layout(yaxis_range=[0,1])
    return fig
  
get_plotly_distribution_plot(tab).show()
```

```{r}
#| warning: false

plot <- get_zoomed_plots(bridge_results_brooklyn_day$tab, c(2408, 2448), c(2762, 2802))
suppressWarnings(print(plot))
```

```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_brooklyn_day$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## Manhattan

```{r}
manhattan_day_prior_params <- list(prior_a = 1/2, prior_b = 0)
bridge_results_manhattan_day <- get_bridge_day_analysis("manhattan", data_long, 0, 5500, manhattan_day_prior_params)
fwrite(bridge_results_manhattan_day$tab, "data/manhattan_full_tab_day.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/manhattan_full_tab_day.csv")
get_plotly_distribution_plot(tab).show()
```

```{r}
#| warning: false

plot <- get_zoomed_plots(bridge_results_manhattan_day$tab, c(4056, 4116), c(5829, 5889))
suppressWarnings(print(plot))
```

```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_manhattan_day$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## Queensboro

```{r}
queensboro_day_prior_params <- list(prior_a = 1/2, prior_b = 0)
bridge_results_queensboro_day <- get_bridge_day_analysis("queensboro", data_long,  0, 5500, queensboro_day_prior_params)
fwrite(bridge_results_queensboro_day$tab, "data/queensboro_full_tab_day.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/queensboro_full_tab_day.csv")
get_plotly_distribution_plot(tab).show()
```

```{r}
#| warning: false

plot <- get_zoomed_plots(bridge_results_queensboro_day$tab, c(3617, 3657), c(4901, 4943))
suppressWarnings(print(plot))
```

```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_queensboro_day$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## Williamsburg

```{r}
williamsburg_day_prior_params <- list(prior_a = 1/2, prior_b = 0)
bridge_results_williamsburg_day <- get_bridge_day_analysis("williamsburg", data_long, 0, 7000, williamsburg_day_prior_params)
fwrite(bridge_results_williamsburg_day$tab, "data/williamsburg_full_tab_day.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/williamsburg_full_tab_day.csv")
get_plotly_distribution_plot(tab).show()
```

```{r}
#| warning: false

plot <- get_zoomed_plots(bridge_results_williamsburg_day$tab, c(4847, 4887), c(6514, 6564))
suppressWarnings(print(plot))
```

```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_williamsburg_day$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```

## total

```{r}
total_day_prior_params <- list(prior_a = 1/2, prior_b = 0)
bridge_results_total_day <- get_bridge_day_analysis("total", data_long, 14400, 21000, total_day_prior_params)
fwrite(bridge_results_total_day$tab, "data/total_full_tab_day.csv")

```

```{python}
#| column: screen
#| out-width: 100%
tab = pd.read_csv("./data/total_full_tab_day.csv")
get_plotly_distribution_plot(tab).show()
```

```{r}
plot <- get_zoomed_plots(bridge_results_total_day$tab, c(14990, 15050), c(20069, 20129))
suppressWarnings(print(plot))
```

```{r}
#| column: screen
#| out-width: 100%
characteristics_tab <- bridge_results_total_day$characteristics |> get_characteristics_reactable()

card(full_screen = TRUE,
     card_header(
       class = "bg-dark",
       "Distribution characteristics"
     ),
     characteristics_tab)

```
:::


### Conclusion
The aim of this project was to analyze the number of cyclists during 214 days of the year 2016. The analysis of this data can be useful, for example, for planning maintenance, construction of new cycling routes and paths, urban planning, and policy-making.
Personally, I was interested in answers to two questions. The first concerns the percentage decrease in the number of cyclists on days when precipitation was recorded (at least $1 mm^3$). The second question deals with the number of cyclists on weekends versus weekdays. I was interested in whether more people use bicycles for commuting to work or for weekend sports activities.
The Bayesian analysis showed that on rainy days, we can expect roughly a 40% decrease in the number of cyclists.
Another conclusion of the analysis is that significantly more people go cycling during weekdays.

